{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment objective\n",
    "Is differencing technic effective?\n",
    "\n",
    "## Experiment setting\n",
    "compare the result with differencing and without differencing\n",
    "### Dataset\n",
    "train : AAPL, MSFT, NVDA, AMZN, COST stock close price (2000-01-01~2013-12-31)  \n",
    "test : AAPL, MSFT, NVDA, AMZN, COST stock close price (2014-01-01~2023-12-31)\n",
    "\n",
    "### Scenario1\n",
    "forecasting one-step ahead AAPL stock close price based on the past 23 steps on itself and 4 other stocks close price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchmetrics import MeanAbsolutePercentageError\n",
    "from data.dataloader import dataloader_info\n",
    "from utils.utils import load_yaml_config, instantiate_from_config\n",
    "from models.predictor import GRU\n",
    "from data.dataloader import dataloader_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs, description, device):\n",
    "    model.train()\n",
    "    with tqdm(range(num_epochs), total=num_epochs) as pbar:\n",
    "        for _ in pbar:\n",
    "            for data_diff, *_ in dataloader:\n",
    "                x_train = data_diff[:,:-1,:].float().to(device)\n",
    "                y_train = data_diff[:,-1:,0].float().to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_train)\n",
    "                loss = criterion(outputs, y_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            pbar.set_description(f\"{description} loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    l1loss = nn.L1Loss()\n",
    "    l2loss = nn.MSELoss()\n",
    "    mapeloss = MeanAbsolutePercentageError().to(device)\n",
    "    \n",
    "    total_l1 = 0\n",
    "    total_l2 = 0\n",
    "    predictions, ground_truth = [], []\n",
    "    with torch.no_grad():\n",
    "        for data_diff, data_norm, data_mean, data_std  in dataloader:\n",
    "            data_norm = data_norm.to(device)\n",
    "            data_diff = data_diff.to(device)\n",
    "            data_mean = data_mean.to(device)\n",
    "            data_std = data_std.to(device)\n",
    "            batch_size = len(data_diff)\n",
    "            x_diff = data_diff[:, :-1, :].float()\n",
    "            y_true_diff = data_diff[:, -1:, :1].float()\n",
    "            y_pred_diff = model(x_diff).view(-1,1,1)\n",
    "            y_pred_norm = data_norm[:,-2:-1,:1] + y_pred_diff\n",
    "            y_true_norm = data_norm[:,-2:-1,:1] + y_true_diff\n",
    "            \n",
    "            y_pred_unnorm = y_pred_norm * data_std[:, :, :1] + data_mean[:, :, :1]\n",
    "            y_test_unnorm = y_true_norm * data_std[:, :, :1] + data_mean[:, :, :1]\n",
    "            \n",
    "            total_l1 += l1loss(y_pred_unnorm, y_test_unnorm) * batch_size\n",
    "            total_l2 += l2loss(y_pred_unnorm, y_test_unnorm) * batch_size\n",
    "\n",
    "            predictions.append(y_pred_unnorm.cpu().numpy())\n",
    "            ground_truth.append(y_test_unnorm.cpu().numpy())\n",
    "\n",
    "    n_data = len(dataloader.dataset)\n",
    "    total_l1 /= n_data\n",
    "    total_l2 /= n_data\n",
    "    predictions = np.concatenate(predictions).squeeze()\n",
    "    ground_truth = np.concatenate(ground_truth).squeeze()\n",
    "    mape_loss = mapeloss(torch.tensor(predictions), torch.tensor(ground_truth)).item()\n",
    "    \n",
    "    return total_l1.item(), total_l2.item(), mape_loss, predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(score):\n",
    "    l1_mean, l2_mean, mape_mean = np.array(score).mean(0)\n",
    "    l1_std, l2_std, mape_std = np.array(score).std(0)\n",
    "    \n",
    "    score_df = pd.DataFrame(score, columns=[\"MAE\", \"MSE\", \"MAPE\"])\n",
    "    print(score_df)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(f\"MAE : {l1_mean:0.4f}({l1_std:0.4f}) \\nMSE : {l2_mean:0.4f}({l2_std:0.4f}) \\nMAPE : {mape_mean:0.4f}({mape_std:0.4f})\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "configs = load_yaml_config(\"configs/experiments1_w_diff.yaml\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize Diffusion_TS Model\n",
    "diffusion_ts = instantiate_from_config(configs['model']).to(device)\n",
    "diffusion_ts.load_state_dict(torch.load(\"check_points/experiments1_w_diff/DiffusionTS_5000.pth\"))\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloader, dataset\n",
    "dl_info_train = dataloader_info(configs, train=True)\n",
    "dl_info_test = dataloader_info(configs, train=False)\n",
    "\n",
    "dl_train = dl_info_train[\"dataloader\"]\n",
    "ds_train = dl_info_train[\"dataset\"]\n",
    "\n",
    "dl_test = dl_info_test[\"dataloader\"]\n",
    "ds_test = dl_info_test[\"dataset\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baseline loss: 0.013744: 100%|██████████| 5000/5000 [03:05<00:00, 27.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline : L1 loss: 1.33756 \t L2 Loss : 4.90620 \t MAPE loss : 0.01667 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train a baseline predictor\n",
    "predictor_base = GRU(input_dim=5, hidden_dim=50, output_dim=1, num_layers=2).to(device)\n",
    "optimizer_base = Adam(predictor_base.parameters(), lr=0.001)\n",
    "lossfn = nn.L1Loss()\n",
    "\n",
    "train_model(predictor_base, \n",
    "            dl_train, \n",
    "            lossfn, \n",
    "            optimizer_base, \n",
    "            num_epochs=5000, \n",
    "            description=\"Baseline\",\n",
    "            device=device)\n",
    "\n",
    "l1, l2, mape, pred_y, true_y = evaluate_model(predictor_base, dl_test, device=device)\n",
    "print(f\"Baseline : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reverse step from x_T to x_0: 100%|██████████| 100/100 [01:01<00:00,  1.62it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/harim/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1133: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Synthetic loss: 0.009064: 100%|██████████| 5000/5000 [01:55<00:00, 43.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic : L1 loss: 1.18296 \t L2 Loss : 3.90295 \t MAPE loss : 0.01479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reverse step from x_T to x_0: 100%|██████████| 100/100 [01:03<00:00,  1.57it/s]\n",
      "Synthetic loss: 0.010328: 100%|██████████| 5000/5000 [01:56<00:00, 42.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic : L1 loss: 1.12814 \t L2 Loss : 3.71478 \t MAPE loss : 0.01408 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reverse step from x_T to x_0:   3%|▎         | 3/100 [00:02<01:05,  1.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer_base_copy \u001b[38;5;241m=\u001b[39m Adam(predictor_base_copy\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# additional training on synthetic data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m \u001b[43mdiffusion_ts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_mts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(synthetic_data))\n\u001b[1;32m     10\u001b[0m dl_synthetic \u001b[38;5;241m=\u001b[39m DataLoader(synthetic_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/diffusion.py:114\u001b[0m, in \u001b[0;36mDiffusion_TS.generate_mts\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    111\u001b[0m shape \u001b[38;5;241m=\u001b[39m (batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_feat)\n\u001b[1;32m    113\u001b[0m x_T \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(shape, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m--> 114\u001b[0m synthetic_mts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reverse_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_T\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m synthetic_mts\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/diffusion.py:121\u001b[0m, in \u001b[0;36mDiffusion_TS._reverse_process\u001b[0;34m(self, x_T)\u001b[0m\n\u001b[1;32m    119\u001b[0m desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreverse step from x_T to x_0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps)), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimesteps, desc\u001b[38;5;241m=\u001b[39mdesc):\n\u001b[0;32m--> 121\u001b[0m     x_T \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_posterior_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_T\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m x_0_hat \u001b[38;5;241m=\u001b[39m x_T\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_0_hat\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/diffusion.py:129\u001b[0m, in \u001b[0;36mDiffusion_TS._posterior_q\u001b[0;34m(self, x_t, t)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''posterior q(x_{t-1} | x_t, x_0)'''\u001b[39;00m\n\u001b[1;32m    128\u001b[0m batched_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((x_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],), t, device\u001b[38;5;241m=\u001b[39mx_t\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m--> 129\u001b[0m x_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_x_0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m x_0\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4.\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.\u001b[39m)\n\u001b[1;32m    132\u001b[0m post_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_mean(x_0\u001b[38;5;241m=\u001b[39mx_0, x_t\u001b[38;5;241m=\u001b[39mx_t, t\u001b[38;5;241m=\u001b[39mbatched_t)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/diffusion.py:68\u001b[0m, in \u001b[0;36mDiffusion_TS.predict_x_0\u001b[0;34m(self, x_t, t)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_x_0\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_t, t):\n\u001b[0;32m---> 68\u001b[0m     trend, season \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     x_0_hat \u001b[38;5;241m=\u001b[39m trend \u001b[38;5;241m+\u001b[39m season\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x_0_hat\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/transformer.py:54\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, input, t)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# decoding\u001b[39;00m\n\u001b[1;32m     53\u001b[0m inp_dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpe_decoder(embedding)\n\u001b[0;32m---> 54\u001b[0m output, mean, trend, season \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp_dec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_cond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse(output)\n\u001b[1;32m     56\u001b[0m res_m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/transformer.py:134\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x_emb, t, encoder_output)\u001b[0m\n\u001b[1;32m    132\u001b[0m trend \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((b, c, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_feat), device\u001b[38;5;241m=\u001b[39mx_emb\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)):\n\u001b[0;32m--> 134\u001b[0m     x_emb, residual_mean, residual_trend, residual_season \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblock_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     trend \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual_trend\n\u001b[1;32m    136\u001b[0m     season \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m residual_season\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/transformer.py:186\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x_emb, t, encoder_output)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# decomposition\u001b[39;00m\n\u001b[1;32m    185\u001b[0m x1, x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x_emb)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m trend, season \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseasonal(x2)\n\u001b[1;32m    187\u001b[0m x_emb \u001b[38;5;241m=\u001b[39m x_emb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm(x_emb))\n\u001b[1;32m    188\u001b[0m m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(x_emb, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/models/transformer.py:292\u001b[0m, in \u001b[0;36mTrendBlock.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrend(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m--> 292\u001b[0m     trend_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(x, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoly_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    293\u001b[0m     trend_vals \u001b[38;5;241m=\u001b[39m trend_vals\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trend_vals\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# only synthetic\n",
    "syn_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on synthetic data\n",
    "    synthetic_data = diffusion_ts.generate_mts(batch_size=3000)\n",
    "    synthetic_data = TensorDataset(torch.from_numpy(synthetic_data))\n",
    "    dl_synthetic = DataLoader(synthetic_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_synthetic, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Synthetic\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_syn, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    syn_score.append([l1, l2, mape])\n",
    "    print(f\"Synthetic : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MAE       MSE      MAPE\n",
      "0  1.182964  3.902951  0.014791\n",
      "1  1.128135  3.714777  0.014083\n",
      "----------------------------------------------------\n",
      "MAE : 1.1555(0.0274) \n",
      "MSE : 3.8089(0.0941) \n",
      "MAPE : 0.0144(0.0004)\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_score(syn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/harim/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1133: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Origin loss: 0.013514: 100%|██████████| 5000/5000 [01:57<00:00, 42.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin : L1 loss: 1.28813 \t L2 Loss : 4.53590 \t MAPE loss : 0.01604 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Origin loss: 0.011560: 100%|██████████| 5000/5000 [01:56<00:00, 42.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin : L1 loss: 1.28446 \t L2 Loss : 4.47585 \t MAPE loss : 0.01611 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Origin loss: 0.015524:   2%|▏         | 102/5000 [00:02<01:56, 42.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m origin_data \u001b[38;5;241m=\u001b[39m TensorDataset(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(origin_data))\n\u001b[1;32m     11\u001b[0m dl_origin \u001b[38;5;241m=\u001b[39m DataLoader(origin_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor_base_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdl_origin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlossfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer_base_copy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOrigin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m l1, l2, mape, pred_y, true_y \u001b[38;5;241m=\u001b[39m evaluate_model(predictor_base_copy, dl_test, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     20\u001b[0m origin_score\u001b[38;5;241m.\u001b[39mappend([l1, l2, mape])\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, num_epochs, description, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m x_train \u001b[38;5;241m=\u001b[39m data_diff[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m y_train \u001b[38;5;241m=\u001b[39m data_diff[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x_train)\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_dynamo/decorators.py:50\u001b[0m, in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     48\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:410\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 410\u001b[0m     (filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtrace_rules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_wrapped_call_impl\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m DONT_WRAP_FILES\n\u001b[1;32m    415\u001b[0m ):\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# call to a builtin without a frame for us to capture\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     fn \u001b[38;5;241m=\u001b[39m external_utils\u001b[38;5;241m.\u001b[39mwrap_inline(fn)\n\u001b[1;32m    419\u001b[0m callback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3378\u001b[0m, in \u001b[0;36mcheck\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck\u001b[39m(obj, is_inlined_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_verbose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inlined_call\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mskipped\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3361\u001b[0m, in \u001b[0;36mcheck_verbose\u001b[0;34m(obj, is_inlined_call)\u001b[0m\n\u001b[1;32m   3358\u001b[0m     fi \u001b[38;5;241m=\u001b[39m FunctionInfo(obj, \u001b[38;5;28;01mNone\u001b[39;00m, getfile(obj), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;66;03m# Consulte the central trace rules defined in torch._dynamo.trace_rules.\u001b[39;00m\n\u001b[0;32m-> 3361\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_rules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_inlined_call\u001b[49m\n\u001b[1;32m   3363\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m [UserFunctionVariable, FunctorchHigherOrderVariable]:\n\u001b[1;32m   3365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SkipResult(\n\u001b[1;32m   3366\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minlined according trace_rules.lookup\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3368\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/_dynamo/trace_rules.py:3442\u001b[0m, in \u001b[0;36mlookup_inner\u001b[0;34m(obj, name, filename, is_direct_call)\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_aten_op_or_tensor_method(obj):\n\u001b[1;32m   3441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TorchInGraphFunctionVariable\n\u001b[0;32m-> 3442\u001b[0m rule \u001b[38;5;241m=\u001b[39m \u001b[43mget_torch_obj_rule_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget(obj, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rule\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# only origin\n",
    "origin_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on original data\n",
    "    idx = np.random.permutation(len(ds_train))[:3000]\n",
    "    origin_data = ds_train.data_diff[idx]\n",
    "    origin_data = TensorDataset(torch.from_numpy(origin_data))\n",
    "    dl_origin = DataLoader(origin_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_origin, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Origin\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_ori, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    origin_score.append([l1, l2, mape])\n",
    "    print(f\"Origin : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE : 1.2863(0.0018) \n",
      " MSE : 4.5059(0.0300) \n",
      " MAPE : 0.0161(0.0000)\n"
     ]
    }
   ],
   "source": [
    "print_score(origin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reverse step from x_T to x_0:   0%|          | 0/100 [00:00<?, ?it/s]/home/harim/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "reverse step from x_T to x_0: 100%|██████████| 100/100 [00:30<00:00,  3.24it/s]\n",
      "  0%|          | 0/5000 [00:00<?, ?it/s]/home/harim/Desktop/pyproject/Project_TS_Generation/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:1133: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n",
      "  result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "Ori+Syn loss: 0.010988: 100%|██████████| 5000/5000 [01:56<00:00, 42.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ori+Syn : L1 loss: 1.21880 \t L2 Loss : 4.07234 \t MAPE loss : 0.01513 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reverse step from x_T to x_0:  99%|█████████▉| 99/100 [00:30<00:00,  3.20it/s]"
     ]
    }
   ],
   "source": [
    "# origin+synthetic\n",
    "ori_syn_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on ori+syn data\n",
    "    idx = np.random.permutation(len(ds_train))[:1500]\n",
    "    origin_data = ds_train.data_diff[idx]\n",
    "    synthetic_data = diffusion_ts.generate_mts(batch_size=1500)\n",
    "    ori_syn_data = np.concatenate([origin_data, synthetic_data])\n",
    "    ori_syn_data = TensorDataset(torch.from_numpy(ori_syn_data))\n",
    "    dl_ori_syn = DataLoader(ori_syn_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_ori_syn, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Ori+Syn\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_ori_syn, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    ori_syn_score.append([l1, l2, mape])\n",
    "    print(f\"Ori+Syn : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(ori_syn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, num_epochs, description, device):\n",
    "    model.train()\n",
    "    with tqdm(range(num_epochs), total=num_epochs) as pbar:\n",
    "        for _ in pbar:\n",
    "            for data_norm, *_ in dataloader:\n",
    "                x_train = data_norm[:,:-1,:].float().to(device)\n",
    "                y_train = data_norm[:,-1:,0].float().to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_train)\n",
    "                loss = criterion(outputs, y_train)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            pbar.set_description(f\"{description} loss: {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    l1loss = nn.L1Loss()\n",
    "    l2loss = nn.MSELoss()\n",
    "    mapeloss = MeanAbsolutePercentageError().to(device)\n",
    "    \n",
    "    total_l1 = 0\n",
    "    total_l2 = 0\n",
    "    predictions, ground_truth = [], []\n",
    "    with torch.no_grad():\n",
    "        for data_norm, data_mean, data_std  in dataloader:\n",
    "            data_norm = data_norm.to(device)\n",
    "            data_mean = data_mean.to(device)\n",
    "            data_std = data_std.to(device)\n",
    "            batch_size = len(data_norm)\n",
    "            \n",
    "            x_test = data_norm[:, :-1, :].float()\n",
    "            y_true_norm = data_norm[:, -1:, :1].float()\n",
    "            y_pred_norm = model(x_test).view(-1,1,1)\n",
    "            \n",
    "            y_pred_unnorm = y_pred_norm * data_std[:, :, :1] + data_mean[:, :, :1]\n",
    "            y_true_unnorm = y_true_norm * data_std[:, :, :1] + data_mean[:, :, :1]\n",
    "            \n",
    "            total_l1 += l1loss(y_pred_unnorm, y_true_unnorm) * batch_size\n",
    "            total_l2 += l2loss(y_pred_unnorm, y_true_unnorm) * batch_size\n",
    "\n",
    "            predictions.append(y_pred_unnorm.cpu().numpy())\n",
    "            ground_truth.append(y_true_unnorm.cpu().numpy())\n",
    "\n",
    "    n_data = len(dataloader.dataset)\n",
    "    total_l1 /= n_data\n",
    "    total_l2 /= n_data\n",
    "    predictions = np.concatenate(predictions).squeeze()\n",
    "    ground_truth = np.concatenate(ground_truth).squeeze()\n",
    "    mape_loss = mapeloss(torch.tensor(predictions), torch.tensor(ground_truth)).item()\n",
    "    \n",
    "    return total_l1.item(), total_l2.item(), mape_loss, predictions, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "configs = load_yaml_config(\"configs/experiments1_wo_diff.yaml\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize Diffusion_TS Model\n",
    "diffusion_ts = instantiate_from_config(configs['model']).to(device)\n",
    "diffusion_ts.load_state_dict(torch.load(\"check_points/experiments1_wo_diff/DiffusionTS_5000.pth\"))\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataloader, dataset\n",
    "dl_info_train = dataloader_info(configs, train=True)\n",
    "dl_info_test = dataloader_info(configs, train=False)\n",
    "\n",
    "dl_train = dl_info_train[\"dataloader\"]\n",
    "ds_train = dl_info_train[\"dataset\"]\n",
    "\n",
    "dl_test = dl_info_test[\"dataloader\"]\n",
    "ds_test = dl_info_test[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a baseline predictor\n",
    "predictor_base = GRU(input_dim=5, hidden_dim=50, output_dim=1, num_layers=2).to(device)\n",
    "optimizer_base = Adam(predictor_base.parameters(), lr=0.001)\n",
    "lossfn = nn.L1Loss()\n",
    "train_model(predictor_base, \n",
    "            dl_train, \n",
    "            lossfn, \n",
    "            optimizer_base, \n",
    "            num_epochs=5000, \n",
    "            description=\"Baseline\",\n",
    "            device=device)\n",
    "l1, l2, mape, pred_y, true_y = evaluate_model(predictor_base, dl_test, device=device)\n",
    "print(f\"Baseline : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only synthetic\n",
    "syn_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on synthetic data\n",
    "    synthetic_data = diffusion_ts.generate_mts(batch_size=3000)\n",
    "    synthetic_data = TensorDataset(torch.from_numpy(synthetic_data))\n",
    "    dl_synthetic = DataLoader(synthetic_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_synthetic, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Synthetic\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_syn, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    syn_score.append([l1, l2, mape])\n",
    "    print(f\"Synthetic : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(syn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only origin\n",
    "origin_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on original data\n",
    "    idx = np.random.permutation(len(ds_train))[:3000]\n",
    "    origin_data = ds_train.data[idx]\n",
    "    origin_data = TensorDataset(torch.from_numpy(origin_data))\n",
    "    dl_origin = DataLoader(origin_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_origin, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Origin\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_ori, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    origin_score.append([l1, l2, mape])\n",
    "    print(f\"Origin : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(origin_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin+synthetic\n",
    "ori_syn_score = []\n",
    "for e in range(5):\n",
    "    predictor_base_copy = copy.deepcopy(predictor_base)\n",
    "    optimizer_base_copy = Adam(predictor_base_copy.parameters(), lr=0.001)\n",
    "\n",
    "    # additional training on ori+syn data\n",
    "    idx = np.random.permutation(len(ds_train))[:1500]\n",
    "    origin_data = ds_train.data[idx]\n",
    "    synthetic_data = diffusion_ts.generate_mts(batch_size=1500)\n",
    "    ori_syn_data = np.concatenate([origin_data, synthetic_data])\n",
    "    ori_syn_data = TensorDataset(torch.from_numpy(ori_syn_data))\n",
    "    dl_ori_syn = DataLoader(ori_syn_data, batch_size=batch_size, shuffle=True)\n",
    "    train_model(predictor_base_copy, \n",
    "                dl_ori_syn, \n",
    "                lossfn, \n",
    "                optimizer_base_copy, \n",
    "                num_epochs=5000, \n",
    "                description=\"Ori+Syn\",\n",
    "                device=device)\n",
    "    l1, l2, mape, pred_y_ori_syn, _ = evaluate_model(predictor_base_copy, dl_test, device=device)\n",
    "    ori_syn_score.append([l1, l2, mape])\n",
    "    print(f\"Ori+Syn : L1 loss: {l1:0.5f} \\t L2 Loss : {l2:0.5f} \\t MAPE loss : {mape:0.5f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(ori_syn_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
